{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Terraform-for-data Terraform 101 for data From Zero. By James Woolfenden I've been using Terraform since version 0.5 https://www.hashicorp.com/blog/terraform-0-5/ while that seems a while, I'm still learning and it's still changing. I've used it with all of the main public clouds. The majority of the examples here will target AWS, but no prior knowledge is required. Pre-requisites Terraform 0.12.21 or newer. An editor, VSCode, Atom or equivalent. Resources This site https://jameswoolfenden.github.io/terraform-for-data/ Its repo: https://github.com/JamesWoolfenden/terraform-for-data/ More Terraform lesson site https://jameswoolfenden.github.io/terraform-by-example/ Its repo: https://github.com/JamesWoolfenden/terraform-by-example/ Further work: https://slalom-consulting-ltd.github.io/learn-terraform/ Hashicorps learn site https://learn.hashicorp.com/terraform Note These lessons are aimed at anyone, only familiarity with Git and a code editor [atom or VSCode] is expected. Terraform can be a real handful to type at the CLI, but at least its not called constellation as originally planned.","title":"Home"},{"location":"#terraform-for-data","text":"","title":"Terraform-for-data"},{"location":"#terraform-101-for-data","text":"From Zero. By James Woolfenden I've been using Terraform since version 0.5 https://www.hashicorp.com/blog/terraform-0-5/ while that seems a while, I'm still learning and it's still changing. I've used it with all of the main public clouds. The majority of the examples here will target AWS, but no prior knowledge is required.","title":"Terraform 101 for data"},{"location":"#pre-requisites","text":"Terraform 0.12.21 or newer. An editor, VSCode, Atom or equivalent.","title":"Pre-requisites"},{"location":"#resources","text":"This site https://jameswoolfenden.github.io/terraform-for-data/ Its repo: https://github.com/JamesWoolfenden/terraform-for-data/ More Terraform lesson site https://jameswoolfenden.github.io/terraform-by-example/ Its repo: https://github.com/JamesWoolfenden/terraform-by-example/ Further work: https://slalom-consulting-ltd.github.io/learn-terraform/ Hashicorps learn site https://learn.hashicorp.com/terraform Note These lessons are aimed at anyone, only familiarity with Git and a code editor [atom or VSCode] is expected. Terraform can be a real handful to type at the CLI, but at least its not called constellation as originally planned.","title":"Resources"},{"location":"about/","text":"About Author: James Woolfenden LinkedIn Bio I'm currently working as a Solution Principal for Slalom and based out of London. I have a bit of experience in the DevOps field, I have worked for a number of consultancies directly and indirectly. This is the second of series on Learning about DevOps. Why This is small run through of using Hashicorp Terraform. As a consultant I frequently have to train developers and \"DevOps\" Engineers how, why and when to use it. I started using Terraform from around version 0.5, I was on a Greenfield AWS project and was really struggling with Cloudformation and its tooling. I asked a question on Linkedin on what others were using and the steers I got were Terraform or Ansible. I achieved more in the day after than in the previous week. Hopefully you'll find this book useful. If it's missing or wrong in anyway, log an Issue or even submit a PR. Each Chapter also contains a copy of the code the chapter tries to teach you how to create. I originally wrote this for the pre 0.11 Terraform and I hopefully updated everything to 0.12 and all the samples should work.","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#author-james-woolfenden","text":"LinkedIn","title":"Author: James Woolfenden"},{"location":"about/#bio","text":"I'm currently working as a Solution Principal for Slalom and based out of London. I have a bit of experience in the DevOps field, I have worked for a number of consultancies directly and indirectly. This is the second of series on Learning about DevOps.","title":"Bio"},{"location":"about/#why","text":"This is small run through of using Hashicorp Terraform. As a consultant I frequently have to train developers and \"DevOps\" Engineers how, why and when to use it. I started using Terraform from around version 0.5, I was on a Greenfield AWS project and was really struggling with Cloudformation and its tooling. I asked a question on Linkedin on what others were using and the steers I got were Terraform or Ansible. I achieved more in the day after than in the previous week. Hopefully you'll find this book useful. If it's missing or wrong in anyway, log an Issue or even submit a PR. Each Chapter also contains a copy of the code the chapter tries to teach you how to create. I originally wrote this for the pre 0.11 Terraform and I hopefully updated everything to 0.12 and all the samples should work.","title":"Why"},{"location":"help/","text":"Help If its been useful, let me know. If it out of date or broken also. I'll appreciate it. Or If you think something's missing or contribute? Got a question? File a GitHub issue . Contributing Bug Reports & Feature Requests Please use the issue tracker to report any bugs or file feature requests. Copyrights Copyright \u00a9 2019-2020 Slalom, LLC License Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Contributors James Woolfenden","title":"Help"},{"location":"help/#help","text":"If its been useful, let me know. If it out of date or broken also. I'll appreciate it. Or If you think something's missing or contribute? Got a question? File a GitHub issue .","title":"Help"},{"location":"help/#contributing","text":"","title":"Contributing"},{"location":"help/#bug-reports-feature-requests","text":"Please use the issue tracker to report any bugs or file feature requests.","title":"Bug Reports &amp; Feature Requests"},{"location":"help/#copyrights","text":"Copyright \u00a9 2019-2020 Slalom, LLC","title":"Copyrights"},{"location":"help/#license","text":"Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"help/#contributors","text":"James Woolfenden","title":"Contributors"},{"location":"lesson1/","text":"Lesson 101 Introduction Introduction to Terraform What is Terraform? It's an open-source command line tool for creating infrastructure. Terraform is a declarative second generation Configuration Management tool designed to provision cloud based Infrastructure via Code. What does that mean? It's easier to show you the difference between using the Traditional approach using the CLI and Terraform. First up is creating an AWS EC2 instance via the CLI. $ aws ec2 run-instances --image-id ami-7ad7c21e --count 1 --instance-type t2.micro --key-name basic --region eu-west-2 --subnet-id subnet-05f8f3c120238ca8d { \"Groups\": [], \"Instances\": [ { \"AmiLaunchIndex\": 0, \"ImageId\": \"ami-7ad7c21e\", \"InstanceId\": \"i-0529e7f9f72b02a53\", \"InstanceType\": \"t2.micro\", \"KeyName\": \"basic\", \"LaunchTime\": \"2020-04-21T13:28:11.000Z\", \"Monitoring\": { \"State\": \"disabled\" }, \"Placement\": { \"AvailabilityZone\": \"eu-west-2a\", \"GroupName\": \"\", \"Tenancy\": \"default\" }, \"PrivateDnsName\": \"ip-10-0-0-187.eu-west-2.compute.internal\", \"PrivateIpAddress\": \"10.0.0.187\", \"ProductCodes\": [], \"PublicDnsName\": \"\", \"State\": { \"Code\": 0, \"Name\": \"pending\" }, \"StateTransitionReason\": \"\", \"SubnetId\": \"subnet-05f8f3c120238ca8d\", \"VpcId\": \"vpc-0e2e925de622375b5\", \"Architecture\": \"x86_64\", \"BlockDeviceMappings\": [], \"ClientToken\": \"\", \"EbsOptimized\": false, \"Hypervisor\": \"xen\", \"NetworkInterfaces\": [ { \"Attachment\": { \"AttachTime\": \"2020-04-21T13:28:11.000Z\", \"AttachmentId\": \"eni-attach-0cbcd67ab97add978\", \"DeleteOnTermination\": true, \"DeviceIndex\": 0, \"Status\": \"attaching\" }, \"Description\": \"\", \"Groups\": [ { \"GroupName\": \"default\", \"GroupId\": \"sg-05749b21616ab0cdc\" } ], \"Ipv6Addresses\": [], \"MacAddress\": \"06:2c:00:49:c8:64\", \"NetworkInterfaceId\": \"eni-0898a0bee39c83400\", \"OwnerId\": \"680235478471\", \"PrivateDnsName\": \"ip-10-0-0-187.eu-west-2.compute.internal\", \"PrivateIpAddress\": \"10.0.0.187\", \"PrivateIpAddresses\": [ { \"Primary\": true, \"PrivateDnsName\": \"ip-10-0-0-187.eu-west-2.compute.internal\", \"PrivateIpAddress\": \"10.0.0.187\" } ], \"SourceDestCheck\": true, \"Status\": \"in-use\", \"SubnetId\": \"subnet-05f8f3c120238ca8d\", \"VpcId\": \"vpc-0e2e925de622375b5\", \"InterfaceType\": \"interface\" } ], \"RootDeviceName\": \"/dev/sda1\", \"RootDeviceType\": \"ebs\", \"SecurityGroups\": [ { \"GroupName\": \"default\", \"GroupId\": \"sg-05749b21616ab0cdc\" } ], \"SourceDestCheck\": true, \"StateReason\": { \"Code\": \"pending\", \"Message\": \"pending\" }, \"VirtualizationType\": \"hvm\", \"CpuOptions\": { \"CoreCount\": 1, \"ThreadsPerCore\": 1 }, \"CapacityReservationSpecification\": { \"CapacityReservationPreference\": \"open\" }, \"MetadataOptions\": { \"State\": \"pending\", \"HttpTokens\": \"optional\", \"HttpPutResponseHopLimit\": 1, \"HttpEndpoint\": \"enabled\" } } ], \"OwnerId\": \"680235478471\", \"ReservationId\": \"r-07540918b65b09424\" } I've got a new instance i-0529e7f9f72b02a53, but if I change the provisioned instance, In anyway, there is no easy way of knowing what has changed and there's no way of knowing what it is supposed to be. Below is the same thing In Terraform, in code, stating how the instance should be: resource \"aws_instance\" \"example\" { instance_type = \"t2.micro\" ami = \"ami-7ad7c21e\" subnet_id = \"subnet-05f8f3c120238ca8d\" vpc_security_group_ids = [ \"sg-05749b21616ab0cdc\" , ] } Now If you modify the instance in any way - in this case by adding tags: aws ec2 create-tags --resources i-0529e7f9f72b02a53 --tags Key=Stack,Value=production You can check for configuration drift by using Terraform plan, (this is not possible with the cli) this command will show the difference between your original coded definition and current reality: $terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. aws_instance.example: Refreshing state... [id=i-0529e7f9f72b02a53] ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: # aws_instance.example will be updated in-place ~ resource \"aws_instance\" \"example\" { ami = \"ami-7ad7c21e\" arn = \"arn:aws:ec2:eu-west-2:680235478471:instance/i-0529e7f9f72b02a53\" associate_public_ip_address = false availability_zone = \"eu-west-2a\" cpu_core_count = 1 cpu_threads_per_core = 1 disable_api_termination = false ebs_optimized = false get_password_data = false hibernation = false id = \"i-0529e7f9f72b02a53\" instance_state = \"running\" instance_type = \"t2.micro\" ipv6_address_count = 0 ipv6_addresses = [] key_name = \"basic\" monitoring = false primary_network_interface_id = \"eni-0898a0bee39c83400\" private_dns = \"ip-10-0-0-187.eu-west-2.compute.internal\" private_ip = \"10.0.0.187\" security_groups = [] source_dest_check = true subnet_id = \"subnet-05f8f3c120238ca8d\" ~ tags = { - \"Stack\" = \"production\" -> null } tenancy = \"default\" volume_tags = {} vpc_security_group_ids = [ \"sg-05749b21616ab0cdc\", ] credit_specification { cpu_credits = \"standard\" } metadata_options { http_endpoint = \"enabled\" http_put_response_hop_limit = 1 http_tokens = \"optional\" } root_block_device { delete_on_termination = true encrypted = false iops = 200 volume_id = \"vol-0e3a5e292da87bd32\" volume_size = 8 volume_type = \"io1\" } timeouts {} } Plan: 0 to add, 1 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. Just the Tags are new. This somehow detected the change in configuration. You can eliminate the \"drift\" by executing Terraform Apply again. The Basics In the previous section we use a few Terraform commands against a set of files. If you run Terraform with the help command you will see there a quite a few options: terraform --help Usage: terraform [-version] [-help] <command> [args] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you're just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. Common commands: apply Builds or changes infrastructure console Interactive console for Terraform interpolations destroy Destroy Terraform-managed infrastructure env Workspace management fmt Rewrites config files to canonical format get Download and install modules for the configuration graph Create a visual graph of Terraform resources import Import existing infrastructure into Terraform init Initialize a Terraform working directory login Obtain and save credentials for a remote host logout Remove locally-stored credentials for a remote host output Read an output from a state file plan Generate and show an execution plan providers Prints a tree of the providers used in the configuration refresh Update local state file against real resources show Inspect Terraform state or plan taint Manually mark a resource for recreation untaint Manually unmark a resource as tainted validate Validates the Terraform files version Prints the Terraform version workspace Workspace management All other commands: 0.12upgrade Rewrites pre-0.12 module source code for v0.12 debug Debug output management (experimental) force-unlock Manually unlock the terraform state push Obsolete command for Terraform Enterprise legacy (v1) state Advanced state management Of that list you use small basic sub-set frequently, you need to know, init , apply , destroy and plan . It always starts with init , but that only needs to run initially and if you need a new module or change the state backend. The life-cycle is: The Workflow As just touched upon the basic Workflow is: code->init->apply->destroy Of course this would happen in a git repository, with adds, commits and pushes. More detail on the standard workflow is found here https://www.terraform.io/guides/core-workflow.html . Idempotency As you saw in the earlier example Terraform doesn't create a new resource on every run. It differs from Tools like cloud formation or scripting in that is idempotent. When it fails it stops or fails it doesn't clean up automatically. You can fix your mistake and Terraform will only change what you changed and hopefully what failed in your last run. Nearly all modern configuration management tools are Idempotent. If you execute your AWS command: aws ec2 run-instances --image-id ami-7ad7c21e --count 1 --instance-type t2.micro --key-name basic --region eu-west-2 --subnet-id subnet-05f8f3c120238ca8d What would happen? Yes, you'd get another new instances. This can get expensive if you're not paying close enough attention. This doesn't happen with each invocation in Terraform, each invocation is matched with is resulting Terrafrom.tfstate or its state file which is used to maintain a record of activity. This \"statefile\" is crucial to your use and understanding of how Terraform works. To remove the instance via the cli id have execute a whole new cli command but id also have to find the instance_id. With Terraform its just: Terraform destroy And the account will return to state it was before you created the instance, no orphaned objects ever remain. State When you run an apply a state file terraform.tfstate is made, this records what infrastructure was made. { \"version\" : 4 , \"terraform_version\" : \"0.12.20\" , \"serial\" : 1 , \"lineage\" : \"48a6fad8-28ca-c946-5f42-c46721405781\" , \"outputs\" : {}, \"resources\" : [ { \"mode\" : \"managed\" , \"type\" : \"aws_instance\" , \"name\" : \"example\" , \"provider\" : \"provider.aws\" , \"instances\" : [ { \"schema_version\" : 1 , \"attributes\" : { \"ami\" : \"ami-7ad7c21e\" , \"arn\" : \"arn:aws:ec2:eu-west-2:680235478471:instance/i-0763a257a728d24eb\" , \"associate_public_ip_address\" : false , \"availability_zone\" : \"eu-west-2a\" , \"cpu_core_count\" : 1 , \"cpu_threads_per_core\" : 1 , \"credit_specification\" : [ { \"cpu_credits\" : \"standard\" } ], \"disable_api_termination\" : false , \"ebs_block_device\" : [], \"ebs_optimized\" : false , \"ephemeral_block_device\" : [], \"get_password_data\" : false , \"hibernation\" : false , \"host_id\" : null , \"iam_instance_profile\" : \"\" , \"id\" : \"i-0763a257a728d24eb\" , \"instance_initiated_shutdown_behavior\" : null , \"instance_state\" : \"running\" , \"instance_type\" : \"t2.micro\" , \"ipv6_address_count\" : 0 , \"ipv6_addresses\" : [], \"key_name\" : \"\" , \"metadata_options\" : [ { \"http_endpoint\" : \"enabled\" , \"http_put_response_hop_limit\" : 1 , \"http_tokens\" : \"optional\" } ], \"monitoring\" : false , \"network_interface\" : [], \"network_interface_id\" : null , \"password_data\" : \"\" , \"placement_group\" : \"\" , \"primary_network_interface_id\" : \"eni-0d5fa924c7aebb3b8\" , \"private_dns\" : \"ip-10-0-0-89.eu-west-2.compute.internal\" , \"private_ip\" : \"10.0.0.89\" , \"public_dns\" : \"\" , \"public_ip\" : \"\" , \"root_block_device\" : [ { \"delete_on_termination\" : true , \"encrypted\" : false , \"iops\" : 200 , \"kms_key_id\" : \"\" , \"volume_id\" : \"vol-056aeda90e38c83d0\" , \"volume_size\" : 8 , \"volume_type\" : \"io1\" } ], \"security_groups\" : [], \"source_dest_check\" : true , \"subnet_id\" : \"subnet-05f8f3c120238ca8d\" , \"tags\" : null , \"tenancy\" : \"default\" , \"timeouts\" : null , \"user_data\" : null , \"user_data_base64\" : null , \"volume_tags\" : {}, \"vpc_security_group_ids\" : [ \"sg-05749b21616ab0cdc\" ] }, \"private\" : \"eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMCwidXBkYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==\" } ] } ] } This file is left in your folder when you are using Local state. Local state is the most basic type and should only be used at the start. It doesn't work when your collaborating or have an automatic process - CI. Corrupting it or losing it is also a major pain. You should always use remote state. AWS S3 This is the Old way. Doesn't make so much sense if you're mutli-cloud/api. Create an S3 Bucket. Manage the bucket yourself. IAM and Bucket permissions. Add reference terraform.tf. terraform { backend \"s3\" { bucket = \"mybucket\" key = \"path/to/my/key\" region = \"us-east-1\" } } Terraform cloud This is the new way. Its managed by Hashicorp, so no maintenance overhead and at all and its easy for multi-cloud & multi-account. Its also a gateway to Terraform clouds other capabilities. Add reference terraform.tf to your template. terraform { backend \"remote\" { organization = \"Slalom\" workspaces { name = \"basic-demo-instance\" } } } Then set up the new state backend with: $ terraform init Initializing the backend... Successfully configured the backend \"remote\"! Terraform will automatically use this backend unless the backend configuration changes. Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"aws\" (hashicorp/aws) 2.56.0... Terraform has been successfully initialized! Show workspace: https://app.terraform.io/app/Slalom/workspaces/basic-demo-instance/runs Open your cli and Terraform apply. Takeaways The destroy and apply command always give you a chance to review the changes before they happen. Exercises Go through the Hashicorp Learn site for more basic information https://learn.hashicorp.com/terraform Look at the other verbs that the Terraform cli, how could you use them? Questions Why use IaC? Why use Terraform? Documentation https://www.terraform.io/guides/core-workflow.html https://www.terraform.io/intro/use-cases.html https://www.terraform.io/intro/vs/index.html","title":"Lesson 101 Intro"},{"location":"lesson1/#lesson-101-introduction","text":"","title":"Lesson 101 Introduction"},{"location":"lesson1/#introduction-to-terraform","text":"What is Terraform? It's an open-source command line tool for creating infrastructure. Terraform is a declarative second generation Configuration Management tool designed to provision cloud based Infrastructure via Code. What does that mean? It's easier to show you the difference between using the Traditional approach using the CLI and Terraform. First up is creating an AWS EC2 instance via the CLI. $ aws ec2 run-instances --image-id ami-7ad7c21e --count 1 --instance-type t2.micro --key-name basic --region eu-west-2 --subnet-id subnet-05f8f3c120238ca8d { \"Groups\": [], \"Instances\": [ { \"AmiLaunchIndex\": 0, \"ImageId\": \"ami-7ad7c21e\", \"InstanceId\": \"i-0529e7f9f72b02a53\", \"InstanceType\": \"t2.micro\", \"KeyName\": \"basic\", \"LaunchTime\": \"2020-04-21T13:28:11.000Z\", \"Monitoring\": { \"State\": \"disabled\" }, \"Placement\": { \"AvailabilityZone\": \"eu-west-2a\", \"GroupName\": \"\", \"Tenancy\": \"default\" }, \"PrivateDnsName\": \"ip-10-0-0-187.eu-west-2.compute.internal\", \"PrivateIpAddress\": \"10.0.0.187\", \"ProductCodes\": [], \"PublicDnsName\": \"\", \"State\": { \"Code\": 0, \"Name\": \"pending\" }, \"StateTransitionReason\": \"\", \"SubnetId\": \"subnet-05f8f3c120238ca8d\", \"VpcId\": \"vpc-0e2e925de622375b5\", \"Architecture\": \"x86_64\", \"BlockDeviceMappings\": [], \"ClientToken\": \"\", \"EbsOptimized\": false, \"Hypervisor\": \"xen\", \"NetworkInterfaces\": [ { \"Attachment\": { \"AttachTime\": \"2020-04-21T13:28:11.000Z\", \"AttachmentId\": \"eni-attach-0cbcd67ab97add978\", \"DeleteOnTermination\": true, \"DeviceIndex\": 0, \"Status\": \"attaching\" }, \"Description\": \"\", \"Groups\": [ { \"GroupName\": \"default\", \"GroupId\": \"sg-05749b21616ab0cdc\" } ], \"Ipv6Addresses\": [], \"MacAddress\": \"06:2c:00:49:c8:64\", \"NetworkInterfaceId\": \"eni-0898a0bee39c83400\", \"OwnerId\": \"680235478471\", \"PrivateDnsName\": \"ip-10-0-0-187.eu-west-2.compute.internal\", \"PrivateIpAddress\": \"10.0.0.187\", \"PrivateIpAddresses\": [ { \"Primary\": true, \"PrivateDnsName\": \"ip-10-0-0-187.eu-west-2.compute.internal\", \"PrivateIpAddress\": \"10.0.0.187\" } ], \"SourceDestCheck\": true, \"Status\": \"in-use\", \"SubnetId\": \"subnet-05f8f3c120238ca8d\", \"VpcId\": \"vpc-0e2e925de622375b5\", \"InterfaceType\": \"interface\" } ], \"RootDeviceName\": \"/dev/sda1\", \"RootDeviceType\": \"ebs\", \"SecurityGroups\": [ { \"GroupName\": \"default\", \"GroupId\": \"sg-05749b21616ab0cdc\" } ], \"SourceDestCheck\": true, \"StateReason\": { \"Code\": \"pending\", \"Message\": \"pending\" }, \"VirtualizationType\": \"hvm\", \"CpuOptions\": { \"CoreCount\": 1, \"ThreadsPerCore\": 1 }, \"CapacityReservationSpecification\": { \"CapacityReservationPreference\": \"open\" }, \"MetadataOptions\": { \"State\": \"pending\", \"HttpTokens\": \"optional\", \"HttpPutResponseHopLimit\": 1, \"HttpEndpoint\": \"enabled\" } } ], \"OwnerId\": \"680235478471\", \"ReservationId\": \"r-07540918b65b09424\" } I've got a new instance i-0529e7f9f72b02a53, but if I change the provisioned instance, In anyway, there is no easy way of knowing what has changed and there's no way of knowing what it is supposed to be. Below is the same thing In Terraform, in code, stating how the instance should be: resource \"aws_instance\" \"example\" { instance_type = \"t2.micro\" ami = \"ami-7ad7c21e\" subnet_id = \"subnet-05f8f3c120238ca8d\" vpc_security_group_ids = [ \"sg-05749b21616ab0cdc\" , ] } Now If you modify the instance in any way - in this case by adding tags: aws ec2 create-tags --resources i-0529e7f9f72b02a53 --tags Key=Stack,Value=production You can check for configuration drift by using Terraform plan, (this is not possible with the cli) this command will show the difference between your original coded definition and current reality: $terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. aws_instance.example: Refreshing state... [id=i-0529e7f9f72b02a53] ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: # aws_instance.example will be updated in-place ~ resource \"aws_instance\" \"example\" { ami = \"ami-7ad7c21e\" arn = \"arn:aws:ec2:eu-west-2:680235478471:instance/i-0529e7f9f72b02a53\" associate_public_ip_address = false availability_zone = \"eu-west-2a\" cpu_core_count = 1 cpu_threads_per_core = 1 disable_api_termination = false ebs_optimized = false get_password_data = false hibernation = false id = \"i-0529e7f9f72b02a53\" instance_state = \"running\" instance_type = \"t2.micro\" ipv6_address_count = 0 ipv6_addresses = [] key_name = \"basic\" monitoring = false primary_network_interface_id = \"eni-0898a0bee39c83400\" private_dns = \"ip-10-0-0-187.eu-west-2.compute.internal\" private_ip = \"10.0.0.187\" security_groups = [] source_dest_check = true subnet_id = \"subnet-05f8f3c120238ca8d\" ~ tags = { - \"Stack\" = \"production\" -> null } tenancy = \"default\" volume_tags = {} vpc_security_group_ids = [ \"sg-05749b21616ab0cdc\", ] credit_specification { cpu_credits = \"standard\" } metadata_options { http_endpoint = \"enabled\" http_put_response_hop_limit = 1 http_tokens = \"optional\" } root_block_device { delete_on_termination = true encrypted = false iops = 200 volume_id = \"vol-0e3a5e292da87bd32\" volume_size = 8 volume_type = \"io1\" } timeouts {} } Plan: 0 to add, 1 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. Just the Tags are new. This somehow detected the change in configuration. You can eliminate the \"drift\" by executing Terraform Apply again.","title":"Introduction to Terraform"},{"location":"lesson1/#the-basics","text":"In the previous section we use a few Terraform commands against a set of files. If you run Terraform with the help command you will see there a quite a few options: terraform --help Usage: terraform [-version] [-help] <command> [args] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you're just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. Common commands: apply Builds or changes infrastructure console Interactive console for Terraform interpolations destroy Destroy Terraform-managed infrastructure env Workspace management fmt Rewrites config files to canonical format get Download and install modules for the configuration graph Create a visual graph of Terraform resources import Import existing infrastructure into Terraform init Initialize a Terraform working directory login Obtain and save credentials for a remote host logout Remove locally-stored credentials for a remote host output Read an output from a state file plan Generate and show an execution plan providers Prints a tree of the providers used in the configuration refresh Update local state file against real resources show Inspect Terraform state or plan taint Manually mark a resource for recreation untaint Manually unmark a resource as tainted validate Validates the Terraform files version Prints the Terraform version workspace Workspace management All other commands: 0.12upgrade Rewrites pre-0.12 module source code for v0.12 debug Debug output management (experimental) force-unlock Manually unlock the terraform state push Obsolete command for Terraform Enterprise legacy (v1) state Advanced state management Of that list you use small basic sub-set frequently, you need to know, init , apply , destroy and plan . It always starts with init , but that only needs to run initially and if you need a new module or change the state backend. The life-cycle is:","title":"The Basics"},{"location":"lesson1/#the-workflow","text":"As just touched upon the basic Workflow is: code->init->apply->destroy Of course this would happen in a git repository, with adds, commits and pushes. More detail on the standard workflow is found here https://www.terraform.io/guides/core-workflow.html .","title":"The Workflow"},{"location":"lesson1/#idempotency","text":"As you saw in the earlier example Terraform doesn't create a new resource on every run. It differs from Tools like cloud formation or scripting in that is idempotent. When it fails it stops or fails it doesn't clean up automatically. You can fix your mistake and Terraform will only change what you changed and hopefully what failed in your last run. Nearly all modern configuration management tools are Idempotent. If you execute your AWS command: aws ec2 run-instances --image-id ami-7ad7c21e --count 1 --instance-type t2.micro --key-name basic --region eu-west-2 --subnet-id subnet-05f8f3c120238ca8d What would happen? Yes, you'd get another new instances. This can get expensive if you're not paying close enough attention. This doesn't happen with each invocation in Terraform, each invocation is matched with is resulting Terrafrom.tfstate or its state file which is used to maintain a record of activity. This \"statefile\" is crucial to your use and understanding of how Terraform works. To remove the instance via the cli id have execute a whole new cli command but id also have to find the instance_id. With Terraform its just: Terraform destroy And the account will return to state it was before you created the instance, no orphaned objects ever remain.","title":"Idempotency"},{"location":"lesson1/#state","text":"When you run an apply a state file terraform.tfstate is made, this records what infrastructure was made. { \"version\" : 4 , \"terraform_version\" : \"0.12.20\" , \"serial\" : 1 , \"lineage\" : \"48a6fad8-28ca-c946-5f42-c46721405781\" , \"outputs\" : {}, \"resources\" : [ { \"mode\" : \"managed\" , \"type\" : \"aws_instance\" , \"name\" : \"example\" , \"provider\" : \"provider.aws\" , \"instances\" : [ { \"schema_version\" : 1 , \"attributes\" : { \"ami\" : \"ami-7ad7c21e\" , \"arn\" : \"arn:aws:ec2:eu-west-2:680235478471:instance/i-0763a257a728d24eb\" , \"associate_public_ip_address\" : false , \"availability_zone\" : \"eu-west-2a\" , \"cpu_core_count\" : 1 , \"cpu_threads_per_core\" : 1 , \"credit_specification\" : [ { \"cpu_credits\" : \"standard\" } ], \"disable_api_termination\" : false , \"ebs_block_device\" : [], \"ebs_optimized\" : false , \"ephemeral_block_device\" : [], \"get_password_data\" : false , \"hibernation\" : false , \"host_id\" : null , \"iam_instance_profile\" : \"\" , \"id\" : \"i-0763a257a728d24eb\" , \"instance_initiated_shutdown_behavior\" : null , \"instance_state\" : \"running\" , \"instance_type\" : \"t2.micro\" , \"ipv6_address_count\" : 0 , \"ipv6_addresses\" : [], \"key_name\" : \"\" , \"metadata_options\" : [ { \"http_endpoint\" : \"enabled\" , \"http_put_response_hop_limit\" : 1 , \"http_tokens\" : \"optional\" } ], \"monitoring\" : false , \"network_interface\" : [], \"network_interface_id\" : null , \"password_data\" : \"\" , \"placement_group\" : \"\" , \"primary_network_interface_id\" : \"eni-0d5fa924c7aebb3b8\" , \"private_dns\" : \"ip-10-0-0-89.eu-west-2.compute.internal\" , \"private_ip\" : \"10.0.0.89\" , \"public_dns\" : \"\" , \"public_ip\" : \"\" , \"root_block_device\" : [ { \"delete_on_termination\" : true , \"encrypted\" : false , \"iops\" : 200 , \"kms_key_id\" : \"\" , \"volume_id\" : \"vol-056aeda90e38c83d0\" , \"volume_size\" : 8 , \"volume_type\" : \"io1\" } ], \"security_groups\" : [], \"source_dest_check\" : true , \"subnet_id\" : \"subnet-05f8f3c120238ca8d\" , \"tags\" : null , \"tenancy\" : \"default\" , \"timeouts\" : null , \"user_data\" : null , \"user_data_base64\" : null , \"volume_tags\" : {}, \"vpc_security_group_ids\" : [ \"sg-05749b21616ab0cdc\" ] }, \"private\" : \"eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMCwidXBkYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==\" } ] } ] } This file is left in your folder when you are using Local state. Local state is the most basic type and should only be used at the start. It doesn't work when your collaborating or have an automatic process - CI. Corrupting it or losing it is also a major pain. You should always use remote state.","title":"State"},{"location":"lesson1/#aws-s3","text":"This is the Old way. Doesn't make so much sense if you're mutli-cloud/api. Create an S3 Bucket. Manage the bucket yourself. IAM and Bucket permissions. Add reference terraform.tf. terraform { backend \"s3\" { bucket = \"mybucket\" key = \"path/to/my/key\" region = \"us-east-1\" } }","title":"AWS S3"},{"location":"lesson1/#terraform-cloud","text":"This is the new way. Its managed by Hashicorp, so no maintenance overhead and at all and its easy for multi-cloud & multi-account. Its also a gateway to Terraform clouds other capabilities. Add reference terraform.tf to your template. terraform { backend \"remote\" { organization = \"Slalom\" workspaces { name = \"basic-demo-instance\" } } } Then set up the new state backend with: $ terraform init Initializing the backend... Successfully configured the backend \"remote\"! Terraform will automatically use this backend unless the backend configuration changes. Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"aws\" (hashicorp/aws) 2.56.0... Terraform has been successfully initialized! Show workspace: https://app.terraform.io/app/Slalom/workspaces/basic-demo-instance/runs Open your cli and Terraform apply. Takeaways The destroy and apply command always give you a chance to review the changes before they happen.","title":"Terraform cloud"},{"location":"lesson1/#exercises","text":"Go through the Hashicorp Learn site for more basic information https://learn.hashicorp.com/terraform Look at the other verbs that the Terraform cli, how could you use them?","title":"Exercises"},{"location":"lesson1/#questions","text":"Why use IaC? Why use Terraform?","title":"Questions"},{"location":"lesson1/#documentation","text":"https://www.terraform.io/guides/core-workflow.html https://www.terraform.io/intro/use-cases.html https://www.terraform.io/intro/vs/index.html","title":"Documentation"},{"location":"lesson2/","text":"lesson 02 Hello World Pre-requisite Ensure that you have Terraform and an editor (VScode) installed: At your shell, make a null resource by creating a file called null_resource.helloworld.tf . touch null_resource.helloworld.tf A null resource doesn't do anything by itself and doesn't require any Cloud Provider Authentication. Then add the block below to it. resource \"null_resource\" \"hello_world\" { } You have just created your first Terraform template, but as yet it does nothing. The next step is to add a local executable Provisioner, to give the null resource some utility: resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo 'hello world'\" } } Fairly straighforward? Time to try your work with terraform init at your shell. $ terraform init Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"null\" ( hashicorp/null ) 2 .1.2... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.null: version = \"~> 2.1\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Terraform init is only needed on new templates and when you add modules or change module versions or providers. You don't have to remember it all, Terraform will fail at apply. Now that has been set up, you can try terraform apply , and when prompted, say yes. $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello world'\" ] null_resource.hello_world ( local-exec ) : 'hello world' null_resource.hello_world: Creation complete after 1s [ id = 5019739039794330655 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. You have made a Terraform template that does something! Now check what files you have on your filesystem. ls -al total 1 drwxrwxrwx 1 jim jim 512 Feb 22 06 :59 . drwxrwxrwx 1 jim jim 512 Feb 22 06 :54 .. drwxrwxrwx 1 jim jim 512 Feb 22 06 :56 .terraform -rwxrwxrwx 1 jim jim 139 Feb 22 06 :59 null.helloworld.tf -rwxrwxrwx 1 jim jim 513 Feb 22 06 :59 terraform.tfstate Terraform.tfstate is your local state file .terraform contains your providers and modules[if any]. Refactor We can be and should be more specify, state the exact Provider version required provider.null.tf provider \"null\" { version = \"2.1.2\" } We specify versions so that we reproduce the same result. Specify the TF core version by specifying Terraform version in terraform.tf terraform { required_version = \"0.12.20\" } State files are linked to TF core version, all members of a team using TF need to use the same version. If one upgrades, all must upgrade, so add this to ensure that you mean to. Re-test these changes with a new apply. Real world example resource \"null_resource\" \"waiter\" { depends_on = [ aws_iam_instance_profile . ec 2 profile ] provisioner \"local-exec\" { command = \"sleep 15\" } } This is basically a hack, pretty much any use of a null resources is up to something dubious. In this case AWS was being rubbish and reported that an object was made when it wasn't yet - eventually consistent and so here we are with a sleep statement. I rarely use Provisioners myself these days, they are bad style and a hangover from Terraforms beginnings. Takeaways Naming Versions Provisioners Providers Plan & apply Exercise Change the required_version to \"0.12.25\" and Apply, what happens? Questions When could specifying the Version still be insufficient for repeatability? when the underlying API itself changes and is no longer backwardly compatible, this wont happen very quickly but it will happen. Its also is bound to the version of the Terraform tool you are using. Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Lesson 102 Hello World"},{"location":"lesson2/#lesson-02-hello-world","text":"","title":"lesson 02 Hello World"},{"location":"lesson2/#pre-requisite","text":"Ensure that you have Terraform and an editor (VScode) installed: At your shell, make a null resource by creating a file called null_resource.helloworld.tf . touch null_resource.helloworld.tf A null resource doesn't do anything by itself and doesn't require any Cloud Provider Authentication. Then add the block below to it. resource \"null_resource\" \"hello_world\" { } You have just created your first Terraform template, but as yet it does nothing. The next step is to add a local executable Provisioner, to give the null resource some utility: resource \"null_resource\" \"hello_world\" { provisioner \"local-exec\" { # This is a comment command = \"echo 'hello world'\" } } Fairly straighforward? Time to try your work with terraform init at your shell. $ terraform init Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"null\" ( hashicorp/null ) 2 .1.2... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.null: version = \"~> 2.1\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Terraform init is only needed on new templates and when you add modules or change module versions or providers. You don't have to remember it all, Terraform will fail at apply. Now that has been set up, you can try terraform apply , and when prompted, say yes. $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # null_resource.hello_world will be created + resource \"null_resource\" \"hello_world\" { + id = ( known after apply ) } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes null_resource.hello_world: Creating... null_resource.hello_world: Provisioning with 'local-exec' ... null_resource.hello_world ( local-exec ) : Executing: [ \"cmd\" \"/C\" \"echo 'hello world'\" ] null_resource.hello_world ( local-exec ) : 'hello world' null_resource.hello_world: Creation complete after 1s [ id = 5019739039794330655 ] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. You have made a Terraform template that does something! Now check what files you have on your filesystem. ls -al total 1 drwxrwxrwx 1 jim jim 512 Feb 22 06 :59 . drwxrwxrwx 1 jim jim 512 Feb 22 06 :54 .. drwxrwxrwx 1 jim jim 512 Feb 22 06 :56 .terraform -rwxrwxrwx 1 jim jim 139 Feb 22 06 :59 null.helloworld.tf -rwxrwxrwx 1 jim jim 513 Feb 22 06 :59 terraform.tfstate Terraform.tfstate is your local state file .terraform contains your providers and modules[if any].","title":"Pre-requisite"},{"location":"lesson2/#refactor","text":"We can be and should be more specify, state the exact Provider version required provider.null.tf provider \"null\" { version = \"2.1.2\" } We specify versions so that we reproduce the same result. Specify the TF core version by specifying Terraform version in terraform.tf terraform { required_version = \"0.12.20\" } State files are linked to TF core version, all members of a team using TF need to use the same version. If one upgrades, all must upgrade, so add this to ensure that you mean to. Re-test these changes with a new apply.","title":"Refactor"},{"location":"lesson2/#real-world-example","text":"resource \"null_resource\" \"waiter\" { depends_on = [ aws_iam_instance_profile . ec 2 profile ] provisioner \"local-exec\" { command = \"sleep 15\" } } This is basically a hack, pretty much any use of a null resources is up to something dubious. In this case AWS was being rubbish and reported that an object was made when it wasn't yet - eventually consistent and so here we are with a sleep statement. I rarely use Provisioners myself these days, they are bad style and a hangover from Terraforms beginnings. Takeaways Naming Versions Provisioners Providers Plan & apply","title":"Real world example"},{"location":"lesson2/#exercise","text":"Change the required_version to \"0.12.25\" and Apply, what happens?","title":"Exercise"},{"location":"lesson2/#questions","text":"When could specifying the Version still be insufficient for repeatability? when the underlying API itself changes and is no longer backwardly compatible, this wont happen very quickly but it will happen. Its also is bound to the version of the Terraform tool you are using.","title":"Questions"},{"location":"lesson2/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Documentation"},{"location":"lesson3/","text":"Lesson 102 AWS Authentication and Endpoints In the previous example there was no Auth as there was no Cloud API/Provider. pre-requisites an AWS account IAM user with access keys Setting up basic Auth for AWS/Terraform. Install aws-cli Install aws auth using you access keys $ aws configure AWS Access Key ID [****************ZTLA]: AWS Secret Access Key [****************Z5Pj]: Default region name [eu-west-1]: Default output format [json]: Test Auth You can test your AWS authentication with a basic AWS command: aws s3 ls 2020-04-09 09:38:42 elasticbeanstalk-eu-west-1-680235478471 2020-04-09 09:38:08 whosebucketisitanyway If that is successful we can progress to our task. VPC Endpoint for S3 - PrivateLink A provisioned PrivateLink means that all traffic is routed private to the endpoint rather than over the internet. Add the Provider Create provider.aws.tf provider \"aws\" { region = \"eu-west-1\" version = \"2.54\" } This completes you basic Authentication for AWS and Terraform. Test with: Terraform init Terraform apply Datasources To add a VPC endpoint, we first need to gather some basic information from the account, datasources are very useful for this, create data.tf : data \"aws_vpcs\" \"cluster\" {} data \"aws_region\" \"current\" {} This will return ALL the VPC's is a region as well as what the current region is. Create and AWS resource Add the code to create the S3 Endpoint aws_vpc_endpoint.s3.tf : This uses values from the datasources. resource \"aws_vpc_endpoint\" \"s3\" { vpc_id = element ( tolist ( data . aws_vpcs . cluster . ids ), 0 ) service_name = \"com.amazonaws.${data.aws_region.current.name}.s3\" tags = { \"createdby\" = \"Terraform\" \"Name\" = \"S3\" } } element(tolist(data.aws_vpcs.cluster.ids), 0) will cast to a list and then return the element of the list at 0 - a vpc_id. ${data.aws_region.current.name} will be replaced in Terraform by my aws region eu-west-1 . As you will see when you Terraform apply: ```terraform apply $ terraform apply data.aws_region.current: Refreshing state... data.aws_vpcs.cluster: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_vpc_endpoint.s3 will be created + resource \"aws_vpc_endpoint\" \"s3\" { + cidr_blocks = (known after apply) + dns_entry = (known after apply) + id = (known after apply) + network_interface_ids = (known after apply) + owner_id = (known after apply) + policy = (known after apply) + prefix_list_id = (known after apply) + private_dns_enabled = false + requester_managed = (known after apply) + route_table_ids = (known after apply) + security_group_ids = (known after apply) + service_name = \"com.amazonaws.eu-west-1.s3\" + state = (known after apply) + subnet_ids = (known after apply) + tags = { + \"Name\" = \"S3\" + \"createdby\" = \"Terraform\" } + vpc_endpoint_type = \"Gateway\" + vpc_id = \"vpc-510efa34\" } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes aws_vpc_endpoint.s3: Creating... aws_vpc_endpoint.s3: Creation complete after 6s [id=vpce-0340fd0233d361bde] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: endpoint = { \"cidr_blocks\" = [ \"52.218.0.0/17\", ] \"dns_entry\" = [] \"id\" = \"vpce-0340fd0233d361bde\" \"network_interface_ids\" = [] \"owner_id\" = \"680235478471\" \"policy\" = \"{\\\"Statement\\\":[{\\\"Action\\\":\\\" \\\",\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":\\\" \\\",\\\"Resource\\\":\\\"*\\\"}],\\\"Version\\\":\\\"2008-10-17\\\"}\" \"prefix_list_id\" = \"pl-6da54004\" \"private_dns_enabled\" = false \"requester_managed\" = false \"route_table_ids\" = [] \"security_group_ids\" = [] \"service_name\" = \"com.amazonaws.eu-west-1.s3\" \"state\" = \"available\" \"subnet_ids\" = [] \"tags\" = { \"Name\" = \"S3\" \"createdby\" = \"Terraform\" } \"vpc_endpoint_type\" = \"Gateway\" \"vpc_id\" = \"vpc-510efa34\" } ``` Takeaways datasources token replacement casting and indexing of lists Exercise Add outputs so that you can see all the values for the created resource. Questions What is missing from this to set up access for an EC2 instance to use the Private Link? There's no route, a modification to the route-able is still required. Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Lesson 103 AWS & Privatelink"},{"location":"lesson3/#lesson-102-aws-authentication-and-endpoints","text":"In the previous example there was no Auth as there was no Cloud API/Provider.","title":"Lesson 102 AWS Authentication and Endpoints"},{"location":"lesson3/#pre-requisites","text":"an AWS account IAM user with access keys Setting up basic Auth for AWS/Terraform. Install aws-cli Install aws auth using you access keys $ aws configure AWS Access Key ID [****************ZTLA]: AWS Secret Access Key [****************Z5Pj]: Default region name [eu-west-1]: Default output format [json]:","title":"pre-requisites"},{"location":"lesson3/#test-auth","text":"You can test your AWS authentication with a basic AWS command: aws s3 ls 2020-04-09 09:38:42 elasticbeanstalk-eu-west-1-680235478471 2020-04-09 09:38:08 whosebucketisitanyway If that is successful we can progress to our task.","title":"Test Auth"},{"location":"lesson3/#vpc-endpoint-for-s3-privatelink","text":"A provisioned PrivateLink means that all traffic is routed private to the endpoint rather than over the internet.","title":"VPC Endpoint for S3 - PrivateLink"},{"location":"lesson3/#add-the-provider","text":"Create provider.aws.tf provider \"aws\" { region = \"eu-west-1\" version = \"2.54\" } This completes you basic Authentication for AWS and Terraform. Test with: Terraform init Terraform apply","title":"Add the Provider"},{"location":"lesson3/#datasources","text":"To add a VPC endpoint, we first need to gather some basic information from the account, datasources are very useful for this, create data.tf : data \"aws_vpcs\" \"cluster\" {} data \"aws_region\" \"current\" {} This will return ALL the VPC's is a region as well as what the current region is.","title":"Datasources"},{"location":"lesson3/#create-and-aws-resource","text":"Add the code to create the S3 Endpoint aws_vpc_endpoint.s3.tf : This uses values from the datasources. resource \"aws_vpc_endpoint\" \"s3\" { vpc_id = element ( tolist ( data . aws_vpcs . cluster . ids ), 0 ) service_name = \"com.amazonaws.${data.aws_region.current.name}.s3\" tags = { \"createdby\" = \"Terraform\" \"Name\" = \"S3\" } } element(tolist(data.aws_vpcs.cluster.ids), 0) will cast to a list and then return the element of the list at 0 - a vpc_id. ${data.aws_region.current.name} will be replaced in Terraform by my aws region eu-west-1 . As you will see when you Terraform apply: ```terraform apply $ terraform apply data.aws_region.current: Refreshing state... data.aws_vpcs.cluster: Refreshing state... An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_vpc_endpoint.s3 will be created + resource \"aws_vpc_endpoint\" \"s3\" { + cidr_blocks = (known after apply) + dns_entry = (known after apply) + id = (known after apply) + network_interface_ids = (known after apply) + owner_id = (known after apply) + policy = (known after apply) + prefix_list_id = (known after apply) + private_dns_enabled = false + requester_managed = (known after apply) + route_table_ids = (known after apply) + security_group_ids = (known after apply) + service_name = \"com.amazonaws.eu-west-1.s3\" + state = (known after apply) + subnet_ids = (known after apply) + tags = { + \"Name\" = \"S3\" + \"createdby\" = \"Terraform\" } + vpc_endpoint_type = \"Gateway\" + vpc_id = \"vpc-510efa34\" } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes aws_vpc_endpoint.s3: Creating... aws_vpc_endpoint.s3: Creation complete after 6s [id=vpce-0340fd0233d361bde] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: endpoint = { \"cidr_blocks\" = [ \"52.218.0.0/17\", ] \"dns_entry\" = [] \"id\" = \"vpce-0340fd0233d361bde\" \"network_interface_ids\" = [] \"owner_id\" = \"680235478471\" \"policy\" = \"{\\\"Statement\\\":[{\\\"Action\\\":\\\" \\\",\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":\\\" \\\",\\\"Resource\\\":\\\"*\\\"}],\\\"Version\\\":\\\"2008-10-17\\\"}\" \"prefix_list_id\" = \"pl-6da54004\" \"private_dns_enabled\" = false \"requester_managed\" = false \"route_table_ids\" = [] \"security_group_ids\" = [] \"service_name\" = \"com.amazonaws.eu-west-1.s3\" \"state\" = \"available\" \"subnet_ids\" = [] \"tags\" = { \"Name\" = \"S3\" \"createdby\" = \"Terraform\" } \"vpc_endpoint_type\" = \"Gateway\" \"vpc_id\" = \"vpc-510efa34\" } ``` Takeaways datasources token replacement casting and indexing of lists","title":"Create and AWS resource"},{"location":"lesson3/#exercise","text":"Add outputs so that you can see all the values for the created resource.","title":"Exercise"},{"location":"lesson3/#questions","text":"What is missing from this to set up access for an EC2 instance to use the Private Link? There's no route, a modification to the route-able is still required.","title":"Questions"},{"location":"lesson3/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Documentation"},{"location":"lesson4/","text":"Lesson 103 AWS RDS and SQLServer Modules Like any modern languages, Terraform supports the use of libraries or in Terraform - Modules. You can write you own, or re-use published modules. Hashicorp maintains a public Registry at https://registry.terraform.io . You can save yourself and others a lot of time by using and publishing modules. To create a MSSQL instance in RDS I write all resource myslef or I could re-use the existing module \"jameswoolfenden/rds/aws\" https://registry.terraform.io/modules/JamesWoolfenden/rds/aws/0.1.4 This is implemented in module.sql.tf module \"rds-mssql\" { source = \"jameswoolfenden/rds/aws\" version = \"0.1.4\" common_tags = var . common_tags instance = var . instance instance_password = \"Password123\" storage_encrypted = false subnet_group = var . subnet_group subnet_ids = var . subnet_ids } Add your definitions in variables.tf variable \"instance\" { } variable \"subnet_group\" { } variable \"common_tags\" { } variable \"subnet_ids\" { } And finally your values sqlserver.auto.tfvars , you'll need to supply different subnets to mine: instance = { auto_minor_version_upgrade = false allocated_storage = 20 availability_zone = \"\" backup_retention_period = 7 backup_window = \"23:01-23:31\" copy_tags_to_snapshot = true create_db_parameter_group = false deletion_protection = false engine = \"sqlserver-ex\" engine_version = \"14.00.3223.3.v1\" iam_database_authentication_enabled = false identifier = \"demodb\" iops = 0 instance_class = \"db.t2.micro\" license_model = \"license-included\" monitoring_interval = 0 maintenance_window = \"tue:22:19-tue:22:49\" monitoring_role_arn = \"\" max_allocated_storage = \"1000\" multi_az = false name = \"\" option_group_name = \"default:sqlserver-ex-14-00\" parameter_group_name = \"default.sqlserver-ex-14.0\" password = \"YourPwdShouldBeLongAndSecure!\" performance_insights_enabled = true performance_insights_retention_period = \"7\" port = \"1433\" security_group_names = null skip_final_snapshot = true snapshot_identifier = \"\" storage_type = \"\" timezone = \"Central Standard Time\" username = \"admin\" } common_tags = { \"createdby\" = \"Terrraform\" } subnet_group = [{ name = \"group-1\" name_prefix = null description = \"sql dbs\" }] subnet_ids = [\"subnet-f60eff81\", \"subnet-11438974\", \"subnet-ebd9cead\"] Now when you apply, you will (eventually SQLServer provisioning is slow) create a MSSQL server instance. Takeaways reuse Exercises Create a module of your own. Create an instance using the module and connect to the SQL instance. Automatically obtain the SQL endpoint. Questions Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Lesson 104 AWS RDS MSSQL"},{"location":"lesson4/#lesson-103-aws-rds-and-sqlserver","text":"","title":"Lesson 103 AWS RDS and SQLServer"},{"location":"lesson4/#modules","text":"Like any modern languages, Terraform supports the use of libraries or in Terraform - Modules. You can write you own, or re-use published modules. Hashicorp maintains a public Registry at https://registry.terraform.io . You can save yourself and others a lot of time by using and publishing modules. To create a MSSQL instance in RDS I write all resource myslef or I could re-use the existing module \"jameswoolfenden/rds/aws\" https://registry.terraform.io/modules/JamesWoolfenden/rds/aws/0.1.4 This is implemented in module.sql.tf module \"rds-mssql\" { source = \"jameswoolfenden/rds/aws\" version = \"0.1.4\" common_tags = var . common_tags instance = var . instance instance_password = \"Password123\" storage_encrypted = false subnet_group = var . subnet_group subnet_ids = var . subnet_ids } Add your definitions in variables.tf variable \"instance\" { } variable \"subnet_group\" { } variable \"common_tags\" { } variable \"subnet_ids\" { } And finally your values sqlserver.auto.tfvars , you'll need to supply different subnets to mine: instance = { auto_minor_version_upgrade = false allocated_storage = 20 availability_zone = \"\" backup_retention_period = 7 backup_window = \"23:01-23:31\" copy_tags_to_snapshot = true create_db_parameter_group = false deletion_protection = false engine = \"sqlserver-ex\" engine_version = \"14.00.3223.3.v1\" iam_database_authentication_enabled = false identifier = \"demodb\" iops = 0 instance_class = \"db.t2.micro\" license_model = \"license-included\" monitoring_interval = 0 maintenance_window = \"tue:22:19-tue:22:49\" monitoring_role_arn = \"\" max_allocated_storage = \"1000\" multi_az = false name = \"\" option_group_name = \"default:sqlserver-ex-14-00\" parameter_group_name = \"default.sqlserver-ex-14.0\" password = \"YourPwdShouldBeLongAndSecure!\" performance_insights_enabled = true performance_insights_retention_period = \"7\" port = \"1433\" security_group_names = null skip_final_snapshot = true snapshot_identifier = \"\" storage_type = \"\" timezone = \"Central Standard Time\" username = \"admin\" } common_tags = { \"createdby\" = \"Terrraform\" } subnet_group = [{ name = \"group-1\" name_prefix = null description = \"sql dbs\" }] subnet_ids = [\"subnet-f60eff81\", \"subnet-11438974\", \"subnet-ebd9cead\"] Now when you apply, you will (eventually SQLServer provisioning is slow) create a MSSQL server instance. Takeaways reuse","title":"Modules"},{"location":"lesson4/#exercises","text":"Create a module of your own. Create an instance using the module and connect to the SQL instance. Automatically obtain the SQL endpoint.","title":"Exercises"},{"location":"lesson4/#questions","text":"","title":"Questions"},{"location":"lesson4/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Documentation"},{"location":"lesson5/","text":"Lesson 104 Terraforming Snowflake This is definitely a much more advanced topic. Install Custom Snowflake provider From https://github.com/chanzuckerberg/terraform-provider-snowflake download your platforms latest provider https://github.com/chanzuckerberg/terraform-provider-snowflake/releases : Or find the example archive examples\\lesson04\\terraform-provider-snowflake_0.11.0_linux_amd64.tar.gz Expand the archive and add it to your Terraform plugins: tar -xvf terraform-provider-snowflake_0.11.0_linux_amd64.tar.gz mv terraform-provider-snowflake_v0.11.0 $HOME /.terraform.d/plugins/linux_amd64/ ToSet-up Authentication with Snowflake, you'll need to add your Snowflake credentials as environmental variables: export SNOWFLAKE_USER = 'yourusername' export SNOWFLAKE_PASSWORD = 'yourpassword' and then create provider.snowflake.tf to managed the Snowflake provider in Terraform. provider \"snowflake\" { account = \"ba82113\" region = \"eu-west-1\" version = \"0.11\" } Adding in your own vales for account and region You can then check authentication using Terraform init and plan . Now that Authectication is validated, then next step is to try and create some Snowflake objects. Starting with Schemas - snowflake_schmea.schema.tf . resource \"snowflake_schema\" \"schema\" { for_each = var . schemas name = each . key database = each . value . database comment = each . value . comment } This template needs to have the variable schema defined, create variables.tf variable \"schemas\" { } And set the values for your schemas with snowflake.auto.tfvars schemas = { \"RAW\" = { database = \"DEMO_DB\" comment = \"contains raw data from our source systems\" } \"ANALYTICS\" = { database = \"DEMO_DB\" comment = \"contains tables and views accessible to analysts and reporting\" } } This should now create 2 schemas, RAW and ANALYTICS (assuming you already have a DEMO_DB). Test as before with Terraform init and plan $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # snowflake_schema.schema[\"ANALYTICS\"] will be created + resource \"snowflake_schema\" \"schema\" { + comment = \"contains tables and views accessible to analysts and reporting\" + data_retention_days = 1 + database = \"DEMO_DB\" + id = ( known after apply ) + is_managed = false + is_transient = false + name = \"ANALYTICS\" } # snowflake_schema.schema[\"RAW\"] will be created + resource \"snowflake_schema\" \"schema\" { + comment = \"contains raw data from our source systems\" + data_retention_days = 1 + database = \"DEMO_DB\" + id = ( known after apply ) + is_managed = false + is_transient = false + name = \"RAW\" } Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Invoke the changes with Terraform apply , selecting yes: Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes snowflake_schema.schema [ \"ANALYTICS\" ] : Creating... snowflake_schema.schema [ \"RAW\" ] : Creating... snowflake_schema.schema [ \"ANALYTICS\" ] : Creation complete after 1s [ id = DEMO_DB | ANALYTICS ] snowflake_schema.schema [ \"RAW\" ] : Creation complete after 1s [ id = DEMO_DB | RAW ] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. Terraform is stating that the Schemas have been created, you can verify the changes in the Snowflake UI, or via SnowSQL with: describe database DEMO_DB ; created_on name kind 2020 - 04 - 21 02 : 33 : 30 . 727 - 0700 ANALYTICS SCHEMA 2020 - 04 - 21 02 : 35 : 19 . 987 - 0700 INFORMATION_SCHEMA SCHEMA 2020 - 04 - 17 02 : 02 : 42 . 057 - 0700 PUBLIC SCHEMA 2020 - 04 - 21 02 : 33 : 30 . 736 - 0700 RAW SCHEMA So thats Terraform creating Snowflake resources via IaC. You can then clean up remove these schemas with Terraform destroy: $ terraform destroy snowflake_schema.schema [ \"RAW\" ] : Refreshing state... [ id = DEMO_DB | RAW ] snowflake_schema.schema [ \"ANALYTICS\" ] : Refreshing state... [ id = DEMO_DB | ANALYTICS ] An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # snowflake_schema.schema[\"ANALYTICS\"] will be destroyed - resource \"snowflake_schema\" \"schema\" { - comment = \"contains tables and views accessible to analysts and reporting\" -> null - data_retention_days = 1 -> null - database = \"DEMO_DB\" -> null - id = \"DEMO_DB|ANALYTICS\" -> null - is_managed = false -> null - is_transient = false -> null - name = \"ANALYTICS\" -> null } # snowflake_schema.schema[\"RAW\"] will be destroyed - resource \"snowflake_schema\" \"schema\" { - comment = \"contains raw data from our source systems\" -> null - data_retention_days = 1 -> null - database = \"DEMO_DB\" -> null - id = \"DEMO_DB|RAW\" -> null - is_managed = false -> null - is_transient = false -> null - name = \"RAW\" -> null } Plan: 0 to add, 0 to change, 2 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only 'yes' will be accepted to confirm. Enter a value: yes snowflake_schema.schema [ \"RAW\" ] : Destroying... [ id = DEMO_DB | RAW ] snowflake_schema.schema [ \"ANALYTICS\" ] : Destroying... [ id = DEMO_DB | ANALYTICS ] snowflake_schema.schema [ \"ANALYTICS\" ] : Destruction complete after 1s snowflake_schema.schema [ \"RAW\" ] : Destruction complete after 1s Destroy complete! Resources: 2 destroyed. Which again can be checked with describing the Database: created_on name kind 2020 - 04 - 21 02 : 38 : 39 . 248 - 0700 INFORMATION_SCHEMA SCHEMA 2020 - 04 - 17 02 : 02 : 42 . 057 - 0700 PUBLIC SCHEMA !!!note \"Takeaways\" - blah - Can create Snowflake db objects via Terraform. - Clean of DB objects by default. Exercise Create Snowflake users via Terraform. Questions Is this any better than using standard SQL tooling? Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html https://github.com/chanzuckerberg/terraform-provider-snowflake https://adam.boscarino.me/posts/terraform-snowflake/","title":"Lesson 105 Snowflake"},{"location":"lesson5/#lesson-104-terraforming-snowflake","text":"This is definitely a much more advanced topic.","title":"Lesson 104 Terraforming Snowflake"},{"location":"lesson5/#install-custom-snowflake-provider","text":"From https://github.com/chanzuckerberg/terraform-provider-snowflake download your platforms latest provider https://github.com/chanzuckerberg/terraform-provider-snowflake/releases : Or find the example archive examples\\lesson04\\terraform-provider-snowflake_0.11.0_linux_amd64.tar.gz Expand the archive and add it to your Terraform plugins: tar -xvf terraform-provider-snowflake_0.11.0_linux_amd64.tar.gz mv terraform-provider-snowflake_v0.11.0 $HOME /.terraform.d/plugins/linux_amd64/ ToSet-up Authentication with Snowflake, you'll need to add your Snowflake credentials as environmental variables: export SNOWFLAKE_USER = 'yourusername' export SNOWFLAKE_PASSWORD = 'yourpassword' and then create provider.snowflake.tf to managed the Snowflake provider in Terraform. provider \"snowflake\" { account = \"ba82113\" region = \"eu-west-1\" version = \"0.11\" } Adding in your own vales for account and region You can then check authentication using Terraform init and plan . Now that Authectication is validated, then next step is to try and create some Snowflake objects. Starting with Schemas - snowflake_schmea.schema.tf . resource \"snowflake_schema\" \"schema\" { for_each = var . schemas name = each . key database = each . value . database comment = each . value . comment } This template needs to have the variable schema defined, create variables.tf variable \"schemas\" { } And set the values for your schemas with snowflake.auto.tfvars schemas = { \"RAW\" = { database = \"DEMO_DB\" comment = \"contains raw data from our source systems\" } \"ANALYTICS\" = { database = \"DEMO_DB\" comment = \"contains tables and views accessible to analysts and reporting\" } } This should now create 2 schemas, RAW and ANALYTICS (assuming you already have a DEMO_DB). Test as before with Terraform init and plan $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # snowflake_schema.schema[\"ANALYTICS\"] will be created + resource \"snowflake_schema\" \"schema\" { + comment = \"contains tables and views accessible to analysts and reporting\" + data_retention_days = 1 + database = \"DEMO_DB\" + id = ( known after apply ) + is_managed = false + is_transient = false + name = \"ANALYTICS\" } # snowflake_schema.schema[\"RAW\"] will be created + resource \"snowflake_schema\" \"schema\" { + comment = \"contains raw data from our source systems\" + data_retention_days = 1 + database = \"DEMO_DB\" + id = ( known after apply ) + is_managed = false + is_transient = false + name = \"RAW\" } Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Invoke the changes with Terraform apply , selecting yes: Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes snowflake_schema.schema [ \"ANALYTICS\" ] : Creating... snowflake_schema.schema [ \"RAW\" ] : Creating... snowflake_schema.schema [ \"ANALYTICS\" ] : Creation complete after 1s [ id = DEMO_DB | ANALYTICS ] snowflake_schema.schema [ \"RAW\" ] : Creation complete after 1s [ id = DEMO_DB | RAW ] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. Terraform is stating that the Schemas have been created, you can verify the changes in the Snowflake UI, or via SnowSQL with: describe database DEMO_DB ; created_on name kind 2020 - 04 - 21 02 : 33 : 30 . 727 - 0700 ANALYTICS SCHEMA 2020 - 04 - 21 02 : 35 : 19 . 987 - 0700 INFORMATION_SCHEMA SCHEMA 2020 - 04 - 17 02 : 02 : 42 . 057 - 0700 PUBLIC SCHEMA 2020 - 04 - 21 02 : 33 : 30 . 736 - 0700 RAW SCHEMA So thats Terraform creating Snowflake resources via IaC. You can then clean up remove these schemas with Terraform destroy: $ terraform destroy snowflake_schema.schema [ \"RAW\" ] : Refreshing state... [ id = DEMO_DB | RAW ] snowflake_schema.schema [ \"ANALYTICS\" ] : Refreshing state... [ id = DEMO_DB | ANALYTICS ] An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: # snowflake_schema.schema[\"ANALYTICS\"] will be destroyed - resource \"snowflake_schema\" \"schema\" { - comment = \"contains tables and views accessible to analysts and reporting\" -> null - data_retention_days = 1 -> null - database = \"DEMO_DB\" -> null - id = \"DEMO_DB|ANALYTICS\" -> null - is_managed = false -> null - is_transient = false -> null - name = \"ANALYTICS\" -> null } # snowflake_schema.schema[\"RAW\"] will be destroyed - resource \"snowflake_schema\" \"schema\" { - comment = \"contains raw data from our source systems\" -> null - data_retention_days = 1 -> null - database = \"DEMO_DB\" -> null - id = \"DEMO_DB|RAW\" -> null - is_managed = false -> null - is_transient = false -> null - name = \"RAW\" -> null } Plan: 0 to add, 0 to change, 2 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only 'yes' will be accepted to confirm. Enter a value: yes snowflake_schema.schema [ \"RAW\" ] : Destroying... [ id = DEMO_DB | RAW ] snowflake_schema.schema [ \"ANALYTICS\" ] : Destroying... [ id = DEMO_DB | ANALYTICS ] snowflake_schema.schema [ \"ANALYTICS\" ] : Destruction complete after 1s snowflake_schema.schema [ \"RAW\" ] : Destruction complete after 1s Destroy complete! Resources: 2 destroyed. Which again can be checked with describing the Database: created_on name kind 2020 - 04 - 21 02 : 38 : 39 . 248 - 0700 INFORMATION_SCHEMA SCHEMA 2020 - 04 - 17 02 : 02 : 42 . 057 - 0700 PUBLIC SCHEMA !!!note \"Takeaways\" - blah - Can create Snowflake db objects via Terraform. - Clean of DB objects by default.","title":"Install Custom Snowflake provider"},{"location":"lesson5/#exercise","text":"Create Snowflake users via Terraform.","title":"Exercise"},{"location":"lesson5/#questions","text":"Is this any better than using standard SQL tooling?","title":"Questions"},{"location":"lesson5/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html https://github.com/chanzuckerberg/terraform-provider-snowflake https://adam.boscarino.me/posts/terraform-snowflake/","title":"Documentation"},{"location":"lesson6/","text":"Lesson 101 !!! note \"Takeaways\" - blah Exercise 1. Questions Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Lesson 101"},{"location":"lesson6/#lesson-101","text":"!!! note \"Takeaways\" - blah","title":"Lesson 101"},{"location":"lesson6/#exercise","text":"1.","title":"Exercise"},{"location":"lesson6/#questions","text":"","title":"Questions"},{"location":"lesson6/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Documentation"},{"location":"lesson7/","text":"Lesson 101 !!! note \"Takeaways\" - blah Exercise 1. Questions Documentation For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Lesson 101"},{"location":"lesson7/#lesson-101","text":"!!! note \"Takeaways\" - blah","title":"Lesson 101"},{"location":"lesson7/#exercise","text":"1.","title":"Exercise"},{"location":"lesson7/#questions","text":"","title":"Questions"},{"location":"lesson7/#documentation","text":"For more on null resource see the Hashicorp docs: https://www.terraform.io/docs/providers/null/resource.html","title":"Documentation"}]}